databricks_resources:
  llm_endpoint_name: databricks-dbrx-instruct
  vector_search_endpoint_name: one-env-shared-endpoint-17
input_example:
  messages:
  - content: What is Apache Spark
    role: user
  - content: Apache spark is a distributed, OSS in-memory computation engine.
    role: assistant
  - content: Does it support streaming?
    role: user
llm_config:
  llm_parameters:
    max_tokens: 1500
    temperature: 0.01
  llm_prompt_template: 'You are a trusted assistant that helps answer questions based
    only on the provided information. If you do not know the answer to a question,
    you truthfully say you do not know.  Here is some context which might or might
    not help you answer: {context}.  Answer directly, do not repeat the question,
    do not start with something like: the answer to the question, do not add AI in
    front of your answer, do not say: here is the answer, do not mention the context
    or the question. Based on this context, answer this question: {question}'
  llm_prompt_template_variables:
  - context
  - question
retriever_config:
  chunk_template: 'Passage: {chunk_text}

    '
  data_pipeline_tag: poc
  embedding_model: databricks-gte-large-en
  parameters:
    k: 3
    query_type: ann
  schema:
    chunk_text: chunked_text
    document_uri: path
    primary_key: chunk_id
  vector_search_index: llm_workshop_2.llm_rag_schema.news_index
